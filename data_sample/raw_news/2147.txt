While his genius may be largely uncontested, Mark Zuckerberg’s vision of Facebook is badly adrift from reality. He paints the social media behemoth he founded in 2004 as a tool “to bring the world closer together,” but in many ways, it has become an indispensable amplification device for people who want to make it known that they hate other people.

Testifying before Congress last Wednesday, Zuckerberg declared: “We do not allow hate groups on Facebook, overall.”

As with many things the Facebook CEO said during his trip to the Hill last week, it was difficult to square this statement with the actual experience of using Facebook. Angry observers were quick to point to anti-Muslim, anti-Semitic, anti-Rohingya, anti-LGBTQ and other hateful groups actively operating on the platform.

Zuckerberg’s claim hit a nerve for me as well. Two months ago, a private Facebook group devoted to alt-right Trump memes inaugurated a campaign of sexual harassment against me. When alerted to the situation, Facebook’s response was, essentially, ¯\_(ツ)_/¯.

The cover photo for the closed Facebook group "Emperor Trumps Dank Meme Stash." Facebook/Emperor Trumps Dank Meme Stash

On Feb. 13, I awoke to find a stream of friend requests on Facebook and a startling message from a man I did not know: “There is some random weirdo posting pictures of you.” He sent me a screenshot of a photo posted in the private Facebook group “Emperor Trumps Dank Meme Stash,” which had more than 72,000 members at the time.

There I was: standing on the beach in Oahu, wearing shorts, a bikini top and a cardigan. I loved that photo ― it was a reminder of a day spent hiking and swimming with my family during our first vacation together in years. I posted it on Facebook last April.

I was stunned as I stared at it almost a year later, along with my full name, literally hundreds of comments and a caption that read: “This is going to be a hard one guys. Huffington Post reporter, smash or pass?”

A cropped copy of my photo posted in "Emperor Trumps Dank Meme Stash." Facebook

Immediately, I requested permission to join the closed group and was directed to answer two questions for approval by its administrators: “Where do you fall on the cuck spectrum?” and “Are you a normie?”

I turned back to the man who had alerted me to the photo and asked him to send me screenshots of as many of the responses as possible, so I could email them to the appropriate representatives at Facebook. As is common in the publishing industry, HuffPost and Facebook work closely on products, partnerships and other shared objectives.

“It is a lot of comments,” he warned. “None of them are nice.”

Screenshots of comments left on the "smash or pass" photo, including "smash with a bat for being a cunt." Facebook

It’s difficult to describe how it feels to discover hundreds of complete strangers debating how fuckable you are. Or to see them casually suggest they’d like to “smash,” “pump” and “skullfuck” you as an apparent form of punishment for your gender and job title.

Dozens of my friends and coworkers reported the group to Facebook. Several hours later, Facebook responded to them with a message saying it had discovered content that “doesn’t follow our Community Standards.” It added: “We removed that specific content … instead of the entire group.” But subsequent screenshots showed my photo was still there.

A staff manager at HuffPost also contacted Facebook directly to request that the post be taken down as quickly as possible. His message contained the screenshots of comments and stressed the matter’s urgency. Two days later, a representative followed up and asked him for the link to the post with the photo, which was inaccessible to anyone who did not belong to the private group (and which I had failed to obtain from the growing swarm of “trolls” in my inbox).

The Facebook representative said that without the link, not much could be done. So the harassment continued, and it worsened.

"Shoot some conservative values all over her tits," one commenter wrote. Facebook

As my account was flooded with creepy messages and friend requests (now 890 and counting), one of my colleagues wrote a public Facebook post asking others to report the group, hoping that it might expedite the process of getting my picture removed. Soon enough, the trolls found her profile, too.

“We’ll just post your pic and do a smash or pass,” one man wrote on her status below two other nasty comments. Another appeared in her inbox: “SMASH.” It was clear that she was also being targeted in “Emperor Trumps Dank Meme Stash.” She deactivated her account.

My photo remained posted in the group for at least six days ― long enough for it to garner even more attention and be shared to at least three other pages. So after nearly a week of apparent inaction from Facebook, I got in touch with one of the group’s administrators, who can review reports about members’ posts, remove content and revoke membership as they please. He told me that the picture might have “flown under the radar.”

“Don’t blame me,” he said, after assuring me he had taken the photo down. “Blame Facebook for their stupid reporting system.” When I asked him to let me join the group, so I could see for myself that it was gone, he refused.

"Only if she gets deported over the wall, or dropped off at a refugee camp immediately afterwards," someone wrote. Facebook

With a growing network of more than 2 billion users around the globe, Facebook’s role in shaping the way we communicate online cannot be easily overstated. It has public policies in place to penalize those who violate its Community Standards (including posts containing nudity, hate speech and violent or graphic content). These users may have their content removed or their accounts disabled, or may even be reported to law enforcement.

Moderating hate speech is an issue “that we struggle with continuously,” Zuckerberg said last week. “There’s a lot of content flowing through the systems and a lot of reports, and, unfortunately, we don’t always get these things right when people report it to us.”

He vowed that Facebook would have “more than 20,000 people working on security and content review across the company” by the end of the year, acknowledging that “no amount of people that we can hire will be enough to review all of the content.”

But instead of advocating for more moderators, pundits have long been calling for greater transparency surrounding the organization’s internal content review standards to ensure consistent enforcement and accountability ― a plea many say has fallen on deaf ears.

"Smash with a ballgag so she doesn't speak." Facebook

A Guardian investigation into leaked documents from Facebook, including private guidelines for content moderation, revealed last year that phrases like “To snap a bitch’s neck, make sure to apply all your pressure to the middle of her throat” are allowed, while others like “Someone shoot Trump” are not.

The report noted that moderators often have “just 10 seconds” to make a decision when evaluating material. It also said many have concerns about “the inconsistency and peculiar nature of some of the policies,” especially those regarding sexual content.

Experts have cautioned that inadequate moderation practices can have serious consequences, such as fostering a culture of online impunity ― leading sites like Facebook to become breeding grounds and safe havens for harassment.

Whereas trolls used to work under the cover of relative anonymity on sites like 4chan and Reddit, many of the Facebook users who commented on my photo and sent me grotesque messages, astonishingly, felt comfortable enough to do so using their real profiles ― with their real names, photos, locations and even places of employment listed.

"Smash so hard she goes conservative." Facebook

Alejandra, who works at a debt-relief company in Fresno, California, commented: “Smash with a ballgag so she doesn’t speak.” Ironically, in a public bio statement sitting atop her Facebook profile, she has written: “I don’t care who you are if you are kind to me I will be kind to you, it’s that simple.”

Michael, a New York-based account manager who was previously a cadet first lieutenant at a military academy in Pennsylvania, wrote that he would “Smash, but I’ll unload on her face… for the patriarch.” On his professional website, he lists his favorite Bible verse as Psalm 133: “How good and pleasant it is when God’s people live together in unity!”

Far from promoting unity, Facebook is an ideal ecosystem for hate groups to flourish. During Zuckerberg’s appearances on the Hill last week, much was made of his site’s explosive growth and transformation, but from my vantage point, staring at screenshots from “Emperor Trump’s Dank Meme Stash,” Facebook looks remarkably unevolved. A platform that grew out of a “hot or not” women-ranking site is now a place for users to debate “smash or pass.”

Upon receiving a request for comment for this article on Friday ― two months after HuffPost initially alerted Facebook to the situation ― the organization said it would review “Emperor Trump’s Dank Meme Stash.” By day’s end, the group was taken down.

“As groups evolve, we can evaluate their activity over time,” a spokesperson said in a statement that evening. “We have removed this group for violating our policies.”